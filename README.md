# k-NN Classification on Iris Dataset ğŸŒ¸

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/akshatdanve/iris-kNN-classification/blob/main/k_NN_Classification_on_Iris_Dataset.ipynb)

This project applies the **k-Nearest Neighbors (k-NN)** algorithm to classify the famous **Iris dataset** into its three species: *Setosa*, *Versicolor*, and *Virginica*. It walks through the end-to-end process of data preprocessing, model training, evaluation, and visualization â€” all implemented in **Google Colab**.

---

## ğŸ“Œ Project Overview

* Implemented the **k-NN classifier** using `scikit-learn`.
* Explored **data visualization** to understand feature distributions.
* Tuned the value of **k** to optimize model accuracy.
* Evaluated the model using **confusion matrix**, **classification report**, and accuracy score.
* Entire workflow is neatly documented and reproducible in a Colab notebook.

This project demonstrates how a simple, distance-based algorithm like k-NN can achieve strong performance on a classical dataset.

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ k_NN_Classification_on_Iris_Dataset.ipynb   # Google Colab Notebook with full implementation
â”œâ”€â”€ README.md                                   # Project documentation
```

---

## ğŸ“Š Dataset

* The [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) is one of the most well-known datasets in machine learning.
* Features:

  * Sepal length
  * Sepal width
  * Petal length
  * Petal width
* Target:

  * Iris-setosa
  * Iris-versicolor
  * Iris-virginica

---

## ğŸš€ Usage

1. Open the notebook directly in **Google Colab**:

   * Upload the `.ipynb` file to your Google Drive
   * Right-click â†’ *Open with* â†’ *Google Colaboratory*

2. Run all cells to reproduce results.
   Youâ€™ll see:

   * Data exploration and visualization
   * Model training with k-NN
   * Performance evaluation

---

## ğŸ“ˆ Results

* Achieved **~95â€“97%** accuracy with the optimal **k** value.
* Demonstrated strong classification performance and clear decision boundaries between species.
* Shows how k-NN handles multi-class classification effectively.

---

## ğŸ”‘ Key Learnings

* The role of **feature scaling** in distance-based algorithms.
* How the choice of **k** affects bias-variance trade-off.
* Visual insights into class separability in the Iris dataset.

---

## ğŸ› ï¸ Technologies Used

* Google Colab (Python 3)
* NumPy
* Pandas
* Matplotlib / Seaborn
* scikit-learn

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!
Feel free to fork this repo and submit a pull request.

---

## ğŸ™ Acknowledgements

* The [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) from the UCI Machine Learning Repository
* [scikit-learn](https://scikit-learn.org/stable/) for machine learning utilities
* [Matplotlib](https://matplotlib.org/) and [Seaborn](https://seaborn.pydata.org/) for data visualization
* [Google Colab](https://colab.research.google.com/) for providing a free and convenient development environment

---

## ğŸ‘¨â€ğŸ’» Author

**Akshat Danve**

* ğŸŒ [GitHub](https://github.com/akshatdanve)
* ğŸ”— [LinkedIn](https://www.linkedin.com/in/akshat-danve/)
* âœ‰ï¸ [Email](mailto:akshatdanve47@gmail.com)

---


